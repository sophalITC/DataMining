{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Web-Scraping.ipynb","provenance":[],"authorship_tag":"ABX9TyNtqsA+BNZCRJ/bvUt1hW60"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<h1> Web Scraping </h1>\n","\n","<p> is about extracting data and information from websites. </p>\n","\n","<p> Beautiful Soup is a Python library for pulling data out of HTML and XML files. </p>"],"metadata":{"id":"H5dfO90ZmbCq"}},{"cell_type":"code","source":["!pip install wikipedia"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzXHAnkcjSU9","executionInfo":{"status":"ok","timestamp":1657732424268,"user_tz":-420,"elapsed":5963,"user":{"displayName":"Sereiwathna Ros","userId":"02372919035474836295"}},"outputId":"9f611c3f-e040-4939-ef33-cdcc5aea547e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wikipedia\n","  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=f8d4208c088395fff8547169d1623a1ba83a54b0c07fd0bd7ec2b237eaab5e57\n","  Stored in directory: /root/.cache/pip/wheels/15/93/6d/5b2c68b8a64c7a7a04947b4ed6d89fb557dcc6bc27d1d7f3ba\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qC8QKYEjKgy","executionInfo":{"status":"ok","timestamp":1657733049668,"user_tz":-420,"elapsed":1078,"user":{"displayName":"Sereiwathna Ros","userId":"02372919035474836295"}},"outputId":"59f2d0ff-f78d-486f-e11e-407527d3819d"},"outputs":[{"output_type":"stream","name":"stdout","text":["A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014. Two neural networks contest with each other in a game (in the form of a zero-sum game, where one agent's gain is another agent's loss).Given a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning, fully supervised learning, and reinforcement learning.The core idea of a GAN is based on the \"indirect\" training through the discriminator, another neural network that is able to tell how much an input is \"realistic\", which itself is also being updated dynamically. This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.GANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks. Method The generative network generates candidates while the discriminative network evaluates them. The contest operates in terms of data distributions. Typically, the generative network learns to map from a latent space to a data distribution of interest, while the discriminative network distinguishes candidates produced by the generator from the true data distribution. The generative network's training objective is to increase the error rate of the discriminative network (i.e., \"fool\" the discriminator network by producing novel candidates that the discriminator thinks are not synthesized (are part of the true data distribution)).A known dataset serves as the initial training data for the discriminator. Training it involves presenting it with samples from the training dataset, until it achieves acceptable accuracy. The generator trains based on whether it succeeds in fooling the discriminator. Typically the generator is seeded with randomized input that is sampled from a predefined latent space (e.g. a multivariate normal distribution). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. Independent backpropagation procedures are applied to both networks so that the generator produces better samples, while the discriminator becomes more skilled at flagging synthetic samples. When used for image generation, the generator is typically a deconvolutional neural network, and the discriminator is a convolutional neural network.GANs often suffer from a \"mode collapse\" where they fail to generalize properly, missing entire modes from the input data. For example, a GAN trained on the MNIST dataset containing many samples of each digit, might nevertheless timidly omit a subset of the digits from its output. Some researchers perceive the root problem to be a weak discriminative network that fails to notice the pattern of omission, while others assign blame to a bad choice of objective function. Many solutions have been proposed.Convergence of GANs is an open problem.GANs are implicit generative models, which means that they do not explicitly model the likelihood function nor provide means for finding the latent variable corresponding to a given sample, unlike alternatives such as Flow-based generative model. Applications GAN applications have increased rapidly.= Fashion, art and advertising =GANs can be used to generate art; The Verge wrote in March 2019 that \"The images created by GANs have become the defining look of contemporary AI art.\" GANs can also be used to inpaint photographs or create photos of imaginary fashion models, with no need to hire a model, photographer or makeup artist, or pay for a studio and transportation. GANs have also been used for virtual shadow generation.= Science =GANs can improve astronomical images and simulate gravitational lensing for dark matter research. They were used in 2019 to successfully model the distribution of dark matter in a particular direction in space and to predict the gravitational lensing that will occur.GANs have been proposed as a fast and accurate way of modeling high energy jet formation and modeling showers through calorimeters of high-energy physics experiments. GANs have also been trained to accurately approximate bottlenecks in computationally expensive simulations of particle physics experiments. Applications in the context of present and proposed CERN experiments have demonstrated the potential of these methods for accelerating simulation and/or improving simulation fidelity.= Video games =In 2018, GANs reached the video game modding community, as a method of up-scaling low-resolution 2D textures in old video games by recreating them in 4k or higher resolutions via image training, and then down-sampling them to fit the game's native resolution (with results resembling the supersampling method of anti-aliasing). With proper training, GANs provide a clearer and sharper 2D texture image magnitudes higher in quality than the original, while fully retaining the original's level of details, colors, etc. Known examples of extensive GAN usage include Final Fantasy VIII, Final Fantasy IX, Resident Evil REmake HD Remaster, and Max Payne.= Audio synthesis == Concerns about malicious applications =Concerns have been raised about the potential use of GAN-based human image synthesis for sinister purposes, e.g., to produce fake, possibly incriminating, photographs and videos.GANs can be used to generate unique, realistic profile photos of people who do not exist, in order to automate creation of fake social media profiles.In 2019 the state of California considered and passed on October 3, 2019, the bill AB-602, which bans the use of human image synthesis technologies to make fake pornography without the consent of the people depicted, and bill AB-730, which prohibits distribution of manipulated videos of a political candidate within 60 days of an election. Both bills were authored by Assembly member Marc Berman and signed by Governor Gavin Newsom. The laws went into effect in 2020.DARPA's Media Forensics program studies ways to counteract fake media, including fake media produced using GANs.= Transfer learning =State-of-art transfer learning research use GANs to enforce the alignment of the latent feature space, such as in deep reinforcement learning. This works by feeding the embeddings of the source and target task to the discriminator which tries to guess the context. The resulting loss is then (inversely) backpropagated through the encoder.= Miscellaneous applications =GAN can be used to detect glaucomatous images helping the early diagnosis which is essential to avoid partial or total lossof vision.GANs that produce photorealistic images can be used to visualize interior design, industrial design, shoes, bags, and clothing items or items for computer games' scenes. Such networks were reported to be used by Facebook.GAN's have been used to create forensic facial reconstructions of deceased historical figures.GANs can reconstruct 3D models of objects from images, generate novel objects as 3D point clouds, and model patterns of motion in video.GANs can be used to age face photographs to show how an individual's appearance might change with age.GANs can be used for data augmentation, eg. to improve DNN classifier GANs can also be used to inpaint missing features in maps, transfer map styles in cartography or augment street view imagery.Relevance feedback on GANs can be used to generate images and replace image search systems.A variation of the GANs is used in training a network to generate optimal control inputs to nonlinear dynamical systems. Where the discriminatory network is known as a critic that checks the optimality of the solution and the generative network is known as an Adaptive network that generates the optimal control. The critic and adaptive network train each other to approximate a nonlinear optimal control.GANs have been used to visualize the effect that climate change will have on specific houses.A GAN model called Speech2Face can reconstruct an image of a person's face after listening to their voice.In 2016 GANs were used to generate new molecules for a variety of protein targets implicated in cancer, inflammation, and fibrosis. In 2019 GAN-generated molecules were validated experimentally all the way into mice.Whereas the majority of GAN applications are in image processing, the work has also been done with time-series data. For example, recurrent GANs (R-GANs) have been used to generate energy data for machine learning. History The most direct inspiration for GANs was noise-contrastive estimation, which uses the same loss function as GANs and which Goodfellow studied during his PhD in 2010–2014.Other people had similar ideas but did not develop them similarly. An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo. This idea was never implemented and did not involve stochasticity in the generator and thus was not a generative model. It is now known as a conditional GAN or cGAN. An idea similar to GANs was used to model animal behavior by Li, Gauci and Gross in 2013.Adversarial machine learning has other uses besides generative modeling and can be applied to models other than neural networks. In control theory, adversarial learning based on neural networks was used in 2006 to train robust controllers in a game theoretic sense, by alternating the iterations between a minimizer policy, the controller, and a maximizer policy, the disturbance.In 2017, a GAN was used for image enhancement focusing on realistic textures rather than pixel-accuracy, producing a higher image quality at high magnification. In 2017, the first faces were generated. These were exhibited in February 2018 at the Grand Palais. Faces generated by StyleGAN in 2019 drew comparisons with deepfakes.Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a \"CAN\", for \"creative adversarial network\". A GAN system was used to create the 2018 painting Edmond de Belamy, which sold for US$432,500. An early 2019 article by members of the original CAN team discussed further progress with that system, and gave consideration as well to the overall prospects for an AI-enabled art.In May 2019, researchers at Samsung demonstrated a GAN-based system that produces videos of a person speaking, given only a single photo of that person.In August 2019, a large dataset consisting of 12,197 MIDI songs each with paired lyrics and melody alignment was created for neural melody generation from lyrics using conditional GAN-LSTM (refer to sources at GitHub AI Melody Generation from Lyrics).In May 2020, Nvidia researchers taught an AI system (termed \"GameGAN\") to recreate the game of Pac-Man simply by watching it being played. Classification = Bidirectional GAN =While the standard GAN model learns a mapping from a latent space to the data distribution, inverse models such as Bidirectional GAN (BiGAN)and Adversarial Autoencodersalso learn a mapping from data to the latent space. This inverse mapping allows real or generated data examples to be projected back into the latent space, similar to the encoder of a variational autoencoder. Applications of bidirectional models include semi-supervised learning, interpretable machine learning, and neural machine translation. References  External links Knight, Will. \"5 Big Predictions for Artificial Intelligence in 2017\". MIT Technology Review. Retrieved January 5, 2017.Karras, Tero; Laine, Samuli; Aila, Timo (2018). \"A Style-Based Generator Architecture for Generative Adversarial Networks\". arXiv:1812.04948 [cs.NE].This Person Does Not Exist –  photorealistic images of people who do not exist, generated by StyleGANThis Cat Does Not Exist –  photorealistic images of cats who do not exist, generated by StyleGANWang, Zhengwei; She, Qi; Ward, Tomas E. (2019). \"Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy\". arXiv:1906.01\n"]}],"source":["import wikipedia\n","\n","wiki = wikipedia.page('Generative adversarial network')\n","text = wiki.content\n","\n","text = text.replace('==', '')\n","text = text.replace('\\n', '')[:-12]\n","print(text)\n","f = open(\"nonscraping_gans.txt\", \"a\")\n","f.write(text)\n","f.close()"]},{"cell_type":"code","source":["from urllib.request import urlopen\n","from bs4 import BeautifulSoup\n","import re\n","\n","source = urlopen('https://en.wikipedia.org/wiki/Generative_adversarial_network').read()\n","\n","soup = BeautifulSoup(source,'lxml')\n","soup\n","\n","paras = []\n","for paragraph in soup.find_all('p'):\n","    paras.append(str(paragraph.text))\n","\n","heads = []\n","for head in soup.find_all('span', attrs={'mw-headline'}):\n","    heads.append(str(head.text))\n","\n","\n","text = [val for pair in zip(paras, heads) for val in pair]\n","text = ' '.join(text)\n","\n","\n","text = re.sub(r\"\\[.*?\\]+\", '', text)\n","f = open(\"scraping_gans.txt\", \"a\")\n","f.write(text)\n","f.close()"],"metadata":{"id":"NBB61Z7ik9ut","executionInfo":{"status":"ok","timestamp":1657733200454,"user_tz":-420,"elapsed":491,"user":{"displayName":"Sereiwathna Ros","userId":"02372919035474836295"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"W9TXvzxTl6aq"},"execution_count":null,"outputs":[]}]}